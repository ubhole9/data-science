{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion minning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPG3G+mbIAC8ziRP11x7jkc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ubhole9/data-science/blob/main/emotion_minning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D67p7iWDITgl"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m  spacy download en"
      ],
      "metadata": {
        "id": "cfQyNRbnIjU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import spacy\n",
        "from matplotlib.pyplot import imread\n",
        "from matplotlib import pyplot as pyplot\n",
        "from wordcloud import wordcloud"
      ],
      "metadata": {
        "id": "Pq-oDMEZIw7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book=pd.read_csv(\"/content/apple.txt\",error_bad_lines=False)\n"
      ],
      "metadata": {
        "id": "QrvRkJk-JoA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book = [x.strip() for x in book.x] # remove both the leading and the trailing characters\n",
        "book = [x for x in book if x] # removes empty strings, because they are considered in Python as False\n",
        "book[0:10]\n"
      ],
      "metadata": {
        "id": "CxKJr9JeJ1DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Part Of Speech Tagging\n",
        "#nlp = spacy.load('en')\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "one_block = book[2]\n",
        "doc_block = nlp(one_block)\n",
        "spacy.displacy.render(doc_block, style='ent', jupyter=True)\n"
      ],
      "metadata": {
        "id": "GpAPIEG3KCVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc_block[0:20]:\n",
        "  print(token,token.pos_)"
      ],
      "metadata": {
        "id": "8o4K9apIKG4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering for nouns and verbs only\n",
        "nouns_verbs = [token.text for token in doc_block if token.pos_ in ('NOUN', 'VERB')]\n",
        "print(nouns_verbs[5:25])\n"
      ],
      "metadata": {
        "id": "89am_BcBLbLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting tokens again\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "\n",
        "X = cv.fit_transform(nouns_verbs)\n",
        "sum_words = X.sum(axis=0)\n",
        "words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
        "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "wf_df = pd.DataFrame(words_freq)\n",
        "wf_df.columns = ['word', 'count']\n",
        "\n",
        "wf_df[0:10]  "
      ],
      "metadata": {
        "id": "5gbd9bp0L-9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Visualizing results\n",
        "#Barchart for top 10 nouns + verbs\n",
        "wf_df[0:10].plot.bar(x='word', figsize=(12,8), title='Top verbs and nouns')\n"
      ],
      "metadata": {
        "id": "SGx61IAaMqyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#emotion minning\n"
      ],
      "metadata": {
        "id": "XadGb90oM2Kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment analysis\n",
        "afinn = pd.read_csv('/content/Afinn.csv', sep=',', encoding='latin-1')\n",
        "afinn.shape\n",
        "afinn.head()"
      ],
      "metadata": {
        "id": "9BH3aRQ5Mv-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import string # special operations on strings\n",
        "import spacy # language models\n",
        "\n",
        "from matplotlib.pyplot import imread\n",
        "from matplotlib import pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas\n",
        "book=pd.read_csv(\"apple.txt\",error_bad_lines=False)\n",
        "book = [x.strip() for x in book.x] # remove both the leading and the trailing characters\n",
        "book = [x for x in book if x] # removes empty strings, because they are considered in Python as False\n"
      ],
      "metadata": {
        "id": "WzZ2E5X0NT3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "FK8H3hLcNanz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import tokenize\n",
        "sentences = tokenize.sent_tokenize(\" \".join(book))\n",
        "sentences[5:15]\n"
      ],
      "metadata": {
        "id": "Q_Fgk1sBNg-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_df = pd.DataFrame(sentences, columns=['sentence'])\n",
        "sent_df\n"
      ],
      "metadata": {
        "id": "kT0kpUuhNs13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "affinity_scores = afinn.set_index('word')['value'].to_dict()\n"
      ],
      "metadata": {
        "id": "ssw-Ych_N6F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "affinity_scores"
      ],
      "metadata": {
        "id": "1-HYre6kOmfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Custom function :score each word in a sentence in lemmatised form, \n",
        "#but calculate the score for the whole original sentence.\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "sentiment_lexicon = affinity_scores\n",
        "\n",
        "def calculate_sentiment(text: str = None):\n",
        "    sent_score = 0\n",
        "    if text:\n",
        "        sentence = nlp(text)\n",
        "        print(sentence)\n",
        "        for word in sentence:\n",
        "            sent_score += sentiment_lexicon.get(word.lemma_, 0)\n",
        "    return sent_score\n"
      ],
      "metadata": {
        "id": "8bACF8epOr3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test that it works\n",
        "calculate_sentiment(text = 'amazed')\n"
      ],
      "metadata": {
        "id": "ojcsTQ5ePLfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_df['sentiment_value'] = sent_df['sentence'].apply(calculate_sentiment)\n"
      ],
      "metadata": {
        "id": "wN49qg9MPWRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_df"
      ],
      "metadata": {
        "id": "sF0qjKbGQVd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_df\n",
        "# how many words are in the sentence?\n",
        "sent_df['word_count'] = sent_df['sentence'].str.split().apply(len)\n",
        "sent_df['word_count'].head(10)\n"
      ],
      "metadata": {
        "id": "gDCaiAEdQCl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_df.sort_values(by='sentiment_value').tail(10)\n"
      ],
      "metadata": {
        "id": "rbO_SF4aQWkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment score of the whole review\n",
        "sent_df[sent_df['sentiment_value']<=0].head()\n"
      ],
      "metadata": {
        "id": "TcdxtErrQkiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment score of the whole review\n",
        "sent_df['sentiment_value'].describe()\n"
      ],
      "metadata": {
        "id": "LCaWwtb7QyyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_df[sent_df['sentiment_value']<-5].head()['sentence'].tolist()[0]\n"
      ],
      "metadata": {
        "id": "zt13ps5EQ90W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_df['index']=range(0,len(sent_df))\n"
      ],
      "metadata": {
        "id": "QQ4ozyk0RnjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.distplot(sent_df['sentiment_value'])\n"
      ],
      "metadata": {
        "id": "iEnhDEd3RwNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "sns.lineplot(y='sentiment_value',x='index',data=sent_df)\n"
      ],
      "metadata": {
        "id": "X5aR57AGR64v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_df.plot.scatter(x='word_count', y='sentiment_value', figsize=(8,8), title='Sentence sentiment value to sentence word count')\n"
      ],
      "metadata": {
        "id": "ptgtgXtJSEhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mvCLdiEqSvQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rFk7r6IFTIOM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}